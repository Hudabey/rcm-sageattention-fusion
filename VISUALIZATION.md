# Visual Explanation: HBM Round-trip Elimination

## The Problem: Baseline (Two-Pass)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPU Memory Hierarchy                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Registers/SRAM (Fast, <1 cycle)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â”‚  Step 1: Compute Attention            â”‚                   â”‚
â”‚  â”‚    q, k, v = split(QKV(x))           â”‚                   â”‚
â”‚  â”‚    attn = softmax(q @ k.T)           â”‚                   â”‚
â”‚  â”‚    out = attn @ v                    â”‚                   â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚             â”‚                                                 â”‚
â”‚             â”‚ WRITE (400 cycles)                             â”‚
â”‚             â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚      HBM (Slow, ~400 cycles)         â”‚                   â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â”‚    attn_out: [B, N, C]               â”‚ â—„â”€â”€â”€ Stored!     â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚             â”‚                                                 â”‚
â”‚             â”‚ READ (400 cycles)                              â”‚
â”‚             â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â”‚  Step 2: Apply Skip Connection        â”‚                   â”‚
â”‚  â”‚    c_skip, c_out = coeffs(t)         â”‚                   â”‚
â”‚  â”‚    final = c_skip*x + c_out*attn_out â”‚ â—„â”€â”€â”€ Read X too! â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚             â”‚                                                 â”‚
â”‚             â”‚ WRITE (400 cycles)                             â”‚
â”‚             â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚      HBM (Slow, ~400 cycles)         â”‚                   â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â”‚    final: [B, N, C]                  â”‚ â—„â”€â”€â”€ Stored!     â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total HBM Traffic:
  â€¢ Attention: 1 write (attn_out)
  â€¢ Skip:      2 reads (x, attn_out) + 1 write (final)
  â€¢ TOTAL:     2 reads + 2 writes = 4 HBM operations

Latency: ~1600 cycles (400 Ã— 4)
```

## The Solution: Fused (One-Pass)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPU Memory Hierarchy                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Registers/SRAM (Fast, <1 cycle)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                        â”‚   â”‚
â”‚  â”‚  Step 1: Compute Attention                            â”‚   â”‚
â”‚  â”‚    q, k, v = split(QKV(x))                           â”‚   â”‚
â”‚  â”‚    attn = softmax(q @ k.T)                           â”‚   â”‚
â”‚  â”‚    attn_out = attn @ v                               â”‚   â”‚
â”‚  â”‚                              â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚  â”‚  Step 2: FUSED Epilogue (still in registers!)     â”‚   â”‚
â”‚  â”‚  â”‚    c_skip, c_out = coeffs(t)                      â”‚   â”‚
â”‚  â”‚  â”‚    final = c_skip*x + c_out*attn_out  â—„â”€â”€â”€ Fused!â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚                                             â”‚          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                â”‚              â”‚
â”‚                                                â”‚ WRITE (400)  â”‚
â”‚                                                â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚      HBM (Slow, ~400 cycles)         â”‚                   â”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â”‚    final: [B, N, C]                  â”‚ â—„â”€â”€â”€ Single Writeâ”‚
â”‚  â”‚                                       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                               â”‚
â”‚  âœ“ attn_out NEVER written to HBM!                           â”‚
â”‚  âœ“ Skip applied while data is HOT in registers!             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total HBM Traffic:
  â€¢ Fused:     0 reads (from HBM for skip) + 1 write (final)
  â€¢ TOTAL:     0 reads + 1 write = 1 HBM operation

Latency: ~400 cycles
Speedup: 1600 / 400 = 4x for skip operation!
```

## Key Insight

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚  The skip connection is computationally TRIVIAL:             â”‚
â”‚                                                               â”‚
â”‚    c_skip * x + c_out * attn_out                            â”‚
â”‚    ^^^^^   ^   ^^^^^   ^^^^^^^^^                             â”‚
â”‚    2 multiplications + 1 addition = 3 FLOPs                  â”‚
â”‚                                                               â”‚
â”‚  But in the baseline, we pay 1600 cycles to:                â”‚
â”‚    â€¢ Write attn_out to HBM      (400 cycles)                â”‚
â”‚    â€¢ Read x from HBM            (400 cycles)                â”‚
â”‚    â€¢ Read attn_out from HBM     (400 cycles)                â”‚
â”‚    â€¢ Write final to HBM         (400 cycles)                â”‚
â”‚                                                               â”‚
â”‚  The actual computation (3 FLOPs) takes <1 cycle!           â”‚
â”‚  But the memory traffic takes 1600 cycles!                   â”‚
â”‚                                                               â”‚
â”‚  Memory-bound, not compute-bound! â—„â”€â”€â”€ This is the problem  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Cache Hierarchy Benefits

```
Memory Level       Access Time    Benefit in Fused Implementation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Registers          <1 cycle       âœ“ attn_out stays here!
L1 Cache           ~4 cycles      âœ“ x likely still here from QKV
L2 Cache           ~20 cycles     âœ“ Fallback if L1 evicted
HBM                ~400 cycles    âœ— Only write final result

Baseline:  Hits HBM 4 times
Fused:     Hits HBM 1 time (write only)
```

## Real-World Impact: Video Diffusion

```
Wan2.1-14B Model:
  â€¢ 32 transformer blocks
  â€¢ 81 frames
  â€¢ 4 timesteps
  â€¢ Each block has self-attention + cross-attention

Skip operations per generation:
  32 blocks Ã— 2 attentions Ã— 81 frames Ã— 4 steps = 20,736 skip ops

HBM traffic saved (per generation):
  20,736 ops Ã— 28% reduction Ã— ~1 MB per skip â‰ˆ 5.8 GB saved!

On RTX 5090 (1 TB/s bandwidth):
  5.8 GB / 1000 GB/s = 5.8 ms saved per video

This compounds across multiple videos! ğŸš€
```

## The Fusion Pattern

This pattern applies to ANY residual connection:

```python
# âŒ Baseline (two-pass)
intermediate = expensive_operation(x)
final = cheap_residual(x, intermediate)  # Requires HBM round-trip

# âœ… Fused (one-pass)  
final = fused_operation_with_residual(x)  # Residual in epilogue!
```

**Examples where this helps:**
- ResNet skip connections
- LoRA adapters
- Transformer residuals
- Any `out = f(x) + x` pattern

**Key requirement:** The residual operation must be CHEAP compared to the main operation. Otherwise, you're optimizing the wrong thing!

---

**Remember**: In GPU optimization, it's not about making computation fasterâ€”it's about moving less data!
